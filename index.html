<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Fan Yang</title>
  
  <meta name="author" content="Fan Yang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Fan Yang</name>
              </p>
              <p>I am a PhD student in robotics at <a href="https://robotics.umich.edu/">University of Michigan, Ann Arbor</a> advised by Prof. <a href="https://berenson.robotics.umich.edu/">Dmitry Berenson</a>. I am working on robot manipulation. Previously, I was a master's student in robotics (MSR) at <a href="https://www.ri.cmu.edu/">Robotics Institute of Carnegie Mellon University</a>, where I am advised by Prof. <a href="https://davheld.github.io/">David Held</a>. I was working on safe Reinforcement Learning and manipualtion with Prof. Held. 
              </p>
              <p>
                Prior to Joining CMU, I was an undergraduate student at Tsinghua University majoring in Engineering Mechanics (Qian class). I was also fortunate to have a chance to be advised by Prof. <a href="https://web.ics.purdue.edu/~rvoyles/?_ga=2.20051194.315720916.1666906347-23318965.1666906347">Richard Voyles</a>, Prof. <a href="https://khatib.stanford.edu/">Oussama Khatib</a>, Prof. <a href="https://me.berkeley.edu/people/masayoshi-tomizuka/">Masayoshi Tomizuka</a>, and Prof. <a href="https://sites.google.com/site/thuliuhuaping">Huaping Liu</a>. 
              </p>
              <p style="text-align:center">
                <a href="mailto:fanyangr@umich.edu">Email</a> &nbsp/&nbsp
                <a href="data/cv_Fan_Yang.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=gOE7fdoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/personal_photo.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/personal_photo.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <!-- <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
					<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/safe_rl.gif' alt="clean-usnob" width="160" height="130">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/safemdp">
                <papertitle>Reinforcement Learning in a Safety-Embedded MDP with Trajectory Optimization</papertitle>
              </a>
              <br>
              <strong>Fan Yang</strong>, <a href="https://wenxuan-zhou.github.io/">Wenxuan Zhou</a>, <a href="https://zuxin.me/">Zuxin Liu</a>, <a href="https://www.meche.engineering.cmu.edu/directory/bios/zhao-ding.html">Zhao Ding</a>, <a href="https://davheld.github.io/">David Held</a>
              <br>
              <em>International Conference on Robotics and Automation (ICRA) </em>, 2024
              <br>
              <p> We propose an algorithm where the RL agent operates in a modified MDP, embedded with a trajectory optimization algorithm to ensure safety.</p>
              <p> Keywords: Safe RL, Trajectory Optimization, Markov Decision Process</p>
              <a href="https://arxiv.org/pdf/2310.06903">[Paper]</a>
              <a href="https://github.com/safetyembedded/SafetyEmbeddedMDP">[Code]</a>
              <a href="https://sites.google.com/view/safemdp">[Website]</a>
              <a href="data/safe_rl.bib">[BibTex]</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/subgoal.gif' alt="clean-usnob" width="160" height="130">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://learn-to-race.org/workshop-sl4ad-icml2022/assets/papers/paper_21.pdf">
                <papertitle>Subgoal Diffuser: Coarse-to-fine Subgoal Generation to Guide Model Predictive Control for Robot Manipulation</papertitle>
              </a>
              <br>
              <a href="https://zxhuang97.github.io/">Zixuan Huang</a>, Yating Lin, <strong>Fan Yang</strong>, <a href="https://berenson.robotics.umich.edu/">Dmitry Berenson</a>
              <br>
              <em>International Conference on Robotics and Automation (ICRA) </em>, 2024
              <br>
              <p> We propose a diffusion model that generates subgoals dynamically in a coarse-to-fine manner, trained by random play data.</p>
              <p> Keywords: Diffusion Model, Reachability, Coarse to Fine</p>
              <a href="https://arxiv.org/pdf/2403.13085">[Paper]</a>
              <a href="https://www.youtube.com/watch?v=mPWsLfnp7L4">[Video]</a>
              <a href="https://sites.google.com/view/subgoal-diffuser-mpc">[Website]</a>
              <a href="data/subgoal.bib">[BibTex]</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/hacman.gif' alt="clean-usnob" width="160" height="130">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://hacman-2023.github.io/">
                <papertitle>HACMan: Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation</papertitle>
              </a>
              <br>
              <a href="https://wenxuan-zhou.github.io/">Wenxuan Zhou</a>, Bowen Jiang, <strong>Fan Yang</strong>, <a href="https://cpaxton.github.io/">Chris Paxton*</a>, <a href="https://davheld.github.io/">David Held*</a>
              <br>
              <em>Conference of Robot Learning <span style="color:#FF0000">(Oral)</span></em>, 2023
              <br>
              <p> We propose a spatially-grounded and temporally-abstracted action representation with a hybrid discrete-continuous reinforcement learning framework.</p>
              <p>Keywords: RL with 3D Vision, Action Representation, Contact-rich manipulation</p>
              <a href="https://arxiv.org/abs/2305.03942">[Paper]</a>
              <a href="https://github.com/HACMan-2023/HACMan">[Code]</a>
              <a href="https://hacman-2023.github.io/">[Website]</a>
              <a href="data/hacman.bib">[BibTex]</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/self_paced.jpg'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://learn-to-race.org/workshop-sl4ad-icml2022/assets/papers/paper_21.pdf">
                <papertitle>Self-Paced Policy Optimization with Safety Constraints</papertitle>
              </a>
              <br>
              <strong>Fan Yang</strong>, <a href="https://wenxuan-zhou.github.io/">Wenxuan Zhou</a>, <a href="https://hari-sikchi.github.io/">Harshit Sikchi</a>, <a href="https://davheld.github.io/">David Held</a>
              <br>
              <em>ICML Workshop, Safe Learning for Autonomous Driving</em>, 2022
              <br>
              <a href="data/self_paced.bib">[BibTex]</a>
              <p></p>
              <p>The method of graduating incurring a harder safety constraints can lead to a better performance in safe RL tasks.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/lifelong.jpg'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://proceedings.mlr.press/v164/yang22a/yang22a.pdf">
                <papertitle>Evaluations of the Gap between Supervised and Reinforcement Lifelong Learning on Robotic Manipulation Tasks</papertitle>
              </a>
              <br>
              <strong>Fan Yang</strong>, <a href="https://scholar.google.com/citations?user=5KRbHPMAAAAJ&hl=zh-CN">Chao Yang</a>, <a href="https://sites.google.com/site/thuliuhuaping">Huaping Liu</a>, <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4035.htm">Fuchun Sun</a>
              <br>
              <em>Conference on Robot Learning (CORL)</em>, 2021
              <br>
              <a href="data/lifelong.bib">[BibTex]</a>
              <p></p>
              <p>We develop a benchmark and evaluate the state-of-the-art lifelong learning method on reinforcement learning tasks, especially robotic manipulation tasks. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/fault_aware.jpg'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2011.08728.pdf">
                <papertitle>Fault-aware robust control via adversarial reinforcement learning</papertitle>
              </a>
              <br>
              <strong>Fan Yang</strong>, <a href="https://scholar.google.com/citations?user=5KRbHPMAAAAJ&hl=zh-CN">Chao Yang</a>, Di Guo, <a href="https://sites.google.com/site/thuliuhuaping">Huaping Liu</a>, <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4035.htm">Fuchun Sun</a>
              <br>
              <em>IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)</em>, 2021
              <br>
              <a href="data/fault_aware.bib">[BibTex]</a>
              <p></p>
              <p>An adversarial training algorithm is used to increase the robustness of robot joint damage. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/rain.jpg'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Li_RAIN_Reinforced_Hybrid_Attention_Inference_Network_for_Motion_Forecasting_ICCV_2021_paper.pdf">
                <papertitle>RAIN: Reinforced hybrid attention inference network for motion forecasting</papertitle>
              </a>
              <br>
              <a href="https://jiachenli94.github.io/">Jiachen Li</a>, <strong>Fan Yang</strong>, Hengbo Ma, Srikanth Malla, <a href="https://me.berkeley.edu/people/masayoshi-tomizuka/">Masayoshi Tomizuka</a>, Chiho Choi
              <br>
              <em> International Conference on Computer Vision (ICCV)</em>, 2021
              <br>
              <a href="data/rain.bib">[BibTex]</a>
              <p></p>
              <p>We develop a method that uses RL agent to select important interactions for trajectory prediction in a highly interactive environment. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/evolve_graph.jpg'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://proceedings.neurips.cc/paper/2020/file/e4d8163c7a068b65a64c89bd745ec360-Paper.pdf">
                <papertitle>Evolvegraph: Multi-agent trajectory prediction with dynamic relational reasoning</papertitle>
              </a>
              <br>
              <a href="https://jiachenli94.github.io/">Jiachen Li*</a>, <strong>Fan Yang*</strong>, <a href="https://me.berkeley.edu/people/masayoshi-tomizuka/">Masayoshi Tomizuka</a>, Chiho Choi
              <br>
              <em> Neural Information Processing Systems (NeurIPS)</em>, 2020
              <br>
              <a href="data/evolve_graph.bib">[BibTex]</a>
              <p></p>
              <p>We develop a Graph-Neural-Network-based method captures the interactions between different agents for trajectory prediction in a highly interactive environment. </p>
            </td>
          </tr>

          

          

        </tbody></table>

				
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					

          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr> -->
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                This website adapts from <a href="https://jonbarron.info/">Jon Barron's website</a> 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
